This paper proposed the Continual Flow Pipeline (CFP) architecture to improve the performance of the processor, by supporting large number of in-flight instructions, without actually scaling up the number of registers size of scheduler. The authors addressed the problem in current designs that impedes performance by analyzing experiment results, proposed their new solution, carried out simulations, and analyzed the results.

Due to the growing gap between processor speed and memory latency, time-consuming memory accesses due to cache misses are causing stalls that severely impacts processor performance. To better exploit instruction-level parallelism, it is normally required to have large and complex processor cores to accommodate more cycle-critical structures, namely register files and scheduler. However, this approach is not feasible for lower-end processors. Also, constant die size and power also limits single core sizes. The author started with an analysis of the results on the Checkpoint Processing and Recovery (CPR) architecture, stating that idealizing register files and scheduler simultaneously would significantly speed up the processor. The CFP proposed in this paper, based on CPR, originates from the above observation. It addresses the above problems by allowing small cores to exploit ILP within a large instruction window. Instruction waiting for data after a cache miss, namely slice instructions in the context of this paper, does not block register files or scheduler. Instead, they drain out of the pipeline, and are managed by the Slice Processing Unit (SPU). The SPU manages completed source register values, to release the “completed source registers”. The SPU also manages the data-dependence information of the slice instructions, such that instructions depending on the pending instruction also drain out of the pipeline. In order to free the destination registers of slice instructions, and re-insert the slice instructions back into the pipeline upon data is returned, the CFP is designed to have a back-end physical-to-physical slice remapper, as well as a slice rename filter to facilitate with renaming. For the problem of branch mis-prediction recovery, the CFP uses a checkpoint mechanism, which does not require reexamination, thus avoiding cache pollution. The results on CFP shows a significant improvement over CPR or ROB-based processors, showing a large extent of tolerance towards memory latency. However, the author did acknowledge that CFP have implications on increasing number of instructions executed on the wrong path, as well as consuming more power due to Slice Processing Unit (SPU). Finally, the author states that after significantly reducing structural stalls with SPU, branch prediction accuracy now depends primarily on branch prediction accuracy.

I think this paper made a nice observation on the obstacles impeding processor performance. The author first identified the contradiction between exploiting ILP and core size, and showed experiment results of idealizing register files to pinpoint the bottleneck of processor performance. Then, a new architecture is proposed, along with some implementation details. However, I think some the implementation part is not detailed enough. In addition, the author mentioned only briefly about the implications of CFP. For example, we do not know exactly how much power impact does the SPU induce, considering that power is one of the initial design constraints of this paper.