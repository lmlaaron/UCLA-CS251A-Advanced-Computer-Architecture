This 2001 paper first gives an overview of the factors of chip power consumption, and listed current means of reducing power. Then, the author emphasized the importance of taking power into consideration in early stages of chip design. With emerging physical limitations and new applications demanding more efficient hardware, power have to be elevated to a first-class constraint in designing a chip.

The power consumption within a chip consists of dynamic consumption, short-circuit current, and static leakage. The first term dominates in today's circuits, and is quadratically related to voltage. Decreasing the voltage, however, poses a limit on the chip's working frequency. Such an approach also requires reducing CMOS threshold voltage, which would in turn increase leakage current. Certain micro-architectures, such as the Intel XScale Core, uses scalable voltage to balance between performance and power. However, changing voltage on-the-fly is feasible only when chips can switch frequency quickly, instead of spending time waiting. Consequently, efforts to reduce power have been made in several other perspectives, for example, circuit logic, architecture and operating systems. For circuit logic where clock tree typically consumes one third of the power, many techniques are based on reducing clock tree power. For example, clock gating, half-frequency and half-swing clocks and asynchronous logic. However, all these approaches have their own trade-offs, as clock gating requires more accurate timing analyzers, reducing frequency by half complicates design, and asynchronous brings testing difficulties. From the perspective of architecture, most approaches are based on reducing dynamic power. For example, activating only part of the memory when accessing, encoding address into gray code to reduce bus voltage switches thanks to spatial locality, and parallel processing. Operating systems can also be used to scale voltage, which could either be providing system calls to applications, or the operating system can handle it by itself. Using software can provide fine-grained content-aware voltage adjustments, but introduces coupling between software and hardware. With chips that of higher MIPS/W, new applications can be developed, such as 3G phones. Back in the 2000s, phones typically rely on the inelegant solution of using 2 processors: one chip for general purposes, and a DSP for signal processing. With a chip powerful enough with low power consumption, we can build a convergent architecture that powers the phones we use today. Datacenters also require efficient hardware, but from a perspective of reducing energy costs. 

I think this paper back in 2001 was very insightful, looking back from today, in emphasizing reducing power during chip design. Designing energy-efficient chips for mobile use and to circumvent physical limitations (such as power density) really took off after 2000. Some of the mentioned approaches later prove to be widely used, such as using multicores, parallel computing, and advanced micro-architectures and logics that are more efficient. Also, most of the 3G cell phones also used a single efficient chip, as the author predicted. However, in my knowledge, using operating systems to scale voltage is as prevalent as the previous two approaches. This is probably because it introduces interleaving between software and hardware, and brings complexity. It should be the OS who solely manages a computerâ€™s resource and hide the hardware details from the applications.