This recent paper proposed a new cache hierarchy design called CATCH, which includes a program criticality detection mechanism in hardware, in addition to several prefetchers. The key point in this paper is that with an effective inter-cache prefetcher, L2 cache can be removed, thus leaving chip space to other components. 

Current cache hierarchy implementations assume that, due to significantly higher latency of LLC caches, having a large per-core L2 caches will reduce the number of stalls caused by fetching from LLC. Such designs are also believed to help programs with large code footprints by reducing processor front-end stalls. However, the authors proposed that the prevalent 3-level cache hierarchy is actually an insufficient design, that the L2 cache is redundant to some extent. To verify their statement, the authors gave simulation results on current designs, which showed that increasing L2 capacity instead of LLC size is indeed more beneficial to some extent. However, such a design means that the overall cache seen by each core is limited, and there could be better designs. The new cache design proposed in this paper is based on the observation that in an OOO core, failure to prefetch data that are not on the critical path of the program doesnâ€™t have much impact. The performance of cache prefetch on OOO core mostly depends on critical loads. To identify data on the critical path, the authors proposed to construct the data independence graph of the program at runtime in hardware, with edge weights denoting the number of cycles needed between dependent instructions. After constructing a graph buffer, we can then enumerate the critical path along the graph, and identify which instructions are critical. We record the identical instructions by recording the PC of load instructions on the critical path, together with a saturating confidence counter. Because each node need only store a pointer to the previous node and corresponding costs, we only need about 3KB to storage for critical path enumeration. After identifying critical instructions, a family of TACT prefetchers are proposed, aiming to prefetch data early enough to eliminate stalls, but meanwhile late enough to avoid L1 cache pollution. For data prefetching, the author proposed Cross, Deep Self and Feeder, each tackling a different scenario. Cross prefetches an instruction triggered by another instruction which have same RegSrcBase value, Deep Self prefetches data in strides with same PC which are common in loops, and Feeder exploits data association. Code prefetch is addressed using a run-ahead prefetcher. Experiments were conducted on all 29 SPEC CPU 2006 benchmarks, which showed although removing L2 cache initially degrades performance, adding the TACT prefetcher will improve the overall performance. The authors also gave performance gains contributed by each prefetcher, which showed that the combination of these prefetchers are essential to overall performance. Experiment results also suggested that CATCH brings a fair amount of power savings.

In conclusion, this is a very recent paper proposing a radical change from current memory hierarchies. The authors first identified problems in current designs, proposed their implementations with great detail, and provided experiment results that are intuitive and promising. However, due to its radical design changes, I doubt that such a design will replace current designs in the near future. 
